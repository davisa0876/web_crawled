# Laravel Web Crawler

This is a simple web crawler implemented using the Laravel PHP framework and the Goutte library. This crawler can be used to analyze a website and gather various data points about it.

The code is deployed on Google Cloud Platform

#LINKS:
  - https://challenges-393913.nn.r.appspot.com/ 
  - https://challenges-393913.nn.r.appspot.com/web-crawler
  - https://challenges-393913.nn.r.appspot.com/web-crawler/agencyanalytics

## Extra Option: 

Create a welcome page telling a little about the small system, also I create a option to ask for Crawler between 1 to 6 pages.  Just need to fill the forms with the urls


## Features

- Counts the number of pages crawled
- Counts the number of unique images
- Counts the number of unique internal and external links
- Measures average page load time
- Computes average word count and title length
- Displays HTTP status codes for each page

## Installation

1. Clone the repository

git clone https://github.com/davisa0876/web_crawled.git


2. Install dependencies

composer install


## Installation

You can start the application with the command:

php artisan serve


## Requirements

The app is built with PHP
The crawler is built for this challenge and not from a library
The app is properly deployed to a hosting service
Code is hosted in a public repository, like Github.com
Bonus: Use of PHP 7 or 8 and its features
Bonus: Use of a framework such as Laravel or Phalcon

## What I tried to do

1. High quality and polished code
2. Attention to architecture and organization
3. Accuracy of the crawled information
